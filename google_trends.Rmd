---
title: "Artificial Intelligence Predicts Health Behavior"
subtitle: 'Can Google Trends Predict the Number of Flu Shots in the US?'
author: "Minh Pham"
date: "3/30/2020"
output: pdf_document
geometry: "left=2.5cm,right=2.5cm,top=1cm,bottom=2cm"
longtable: true
header-includes:
- \usepackage{longtable,booktabs,multirow}
- \usepackage[justification=centering]{caption}
- \usepackage{float}
- \floatplacement{figure}{H}
fontsize: 12pt
linestretch: 1.2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,tidy.opts=list(width.cutoff=55),tidy=TRUE, warning = F,message = F)
```


```{r,include=FALSE, echo=FALSE}
library(devtools)
library(readr)
library(pscl)
library(spdep)
library(MASS)
library(readxl)
library(lodown)
library(tidyverse)
library(survey)
library(zoo)
library(dplyr)
library(srvyr)
library(ggplot2)
library(sjstats)
library(quantmod)
library(multiwayvcov)
library(InformationValue)
library(lmtest)
library(mpath)
library(rsq)
library(stargazer)
library(gtsummary)
library(gt)
library(glue)
library(effects)
library(reshape2)
library(ROSE)
library(DataCombine)
```


```{r, include=FALSE, echo=FALSE}
brfss_df12 <- 
    readRDS( file.path( path.expand( "~" ) , "BRFSS" , "2012 main.rds" ) )
brfss_df13 <- 
    readRDS( file.path( path.expand( "~" ) , "BRFSS" , "2013 main.rds" ) )
brfss_df14 <- 
    readRDS( file.path( path.expand( "~" ) , "BRFSS" , "2014 main.rds" ) )
brfss_df15 <- 
    readRDS( file.path( path.expand( "~" ) , "BRFSS" , "2015 main.rds" ) )
brfss_df16 <- 
    readRDS( file.path( path.expand( "~" ) , "BRFSS" , "2016 main.rds" ) )
brfss_df17 <- 
    readRDS( file.path( path.expand( "~" ) , "BRFSS" , "2017 main.rds" ) )
brfss_df18 <- 
    readRDS( file.path( path.expand( "~" ) , "BRFSS" , "2018 main.rds" ) )

brfss_df12$xpsu=as.integer(brfss_df12$xpsu)
brfss_df13$xpsu=as.integer(brfss_df13$xpsu)
brfss_df14$xpsu=as.integer(brfss_df14$xpsu)
brfss_df15$xpsu=as.integer(brfss_df15$xpsu)
brfss_df16$xpsu=as.integer(brfss_df16$xpsu)
brfss_df17$xpsu=as.integer(brfss_df17$xpsu)
brfss_df18$xpsu=as.integer(brfss_df18$xpsu)


# brfss_df18$sex=brfss_df18$sex1


brfss_df1213 <- intersect(colnames(brfss_df12), colnames(brfss_df13))

brfss_df1213 <- rbind(brfss_df12[ , brfss_df1213], brfss_df13[ , brfss_df1213])

brfss_df121314 <- intersect(colnames(brfss_df1213), colnames(brfss_df14))

brfss_df121314 <- rbind(brfss_df1213[ , brfss_df121314], brfss_df14[ , brfss_df121314])

brfss_df12131415 <- intersect(colnames(brfss_df121314), colnames(brfss_df15))

brfss_df12131415 <- rbind(brfss_df121314[ , brfss_df12131415], brfss_df15[ , brfss_df12131415])

brfss_df1213141516 <- intersect(colnames(brfss_df12131415), colnames(brfss_df16))

brfss_df1213141516 <- rbind(brfss_df12131415[ , brfss_df1213141516], brfss_df16[ , brfss_df1213141516])

brfss_df121314151617 <- intersect(colnames(brfss_df1213141516), colnames(brfss_df17))

brfss_df121314151617 <- rbind(brfss_df1213141516[ , brfss_df121314151617], brfss_df17[ , brfss_df121314151617])

brfss_df12131415161718 <- intersect(colnames(brfss_df121314151617), colnames(brfss_df18))

brfss_df12131415161718 <- rbind(brfss_df121314151617[ , brfss_df12131415161718], brfss_df18[ , brfss_df12131415161718])



brfss_df12131415161718$state_name=factor(brfss_df12131415161718$xstate , levels = 
                    c(1, 2, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 
                    21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 
                    37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 49, 50, 51, 53, 54, 
                    55, 56) ,
                    
                labels = 
                    c("ALABAMA", "ALASKA", "ARIZONA", "ARKANSAS", "CALIFORNIA", 
                    "COLORADO", "CONNECTICUT", "DELAWARE", "DISTRICT OF COLUMBIA", 
                    "FLORIDA", "GEORGIA", "HAWAII", "IDAHO", "ILLINOIS", "INDIANA",
                    "IOWA", "KANSAS", "KENTUCKY", "LOUISIANA", "MAINE", "MARYLAND",
                    "MASSACHUSETTS", "MICHIGAN", "MINNESOTA", "MISSISSIPPI", 
                    "MISSOURI", "MONTANA", "NEBRASKA", "NEVADA", "NEW HAMPSHIRE",
                    "NEW JERSEY", "NEW MEXICO", "NEW YORK", "NORTH CAROLINA", 
                    "NORTH DAKOTA", "OHIO", "OKLAHOMA", "OREGON", "PENNSYLVANIA",
                    "RHODE ISLAND", "SOUTH CAROLINA", "SOUTH DAKOTA", "TENNESSEE",
                    "TEXAS", "UTAH", "VERMONT", "VIRGINIA", "WASHINGTON",
                    "WEST VIRGINIA", "WISCONSIN", "WYOMING"))


brfss_df12131415161718s = brfss_df12131415161718 %>% select(xstate,	fmonth,	imonth,	iday,	iyear,	xpsu,	flshtmy2, state_name) 

table(brfss_df12131415161718s$state_name)
```


```{r,include=FALSE, echo=FALSE}
brfss_df12131415161718s$when_flushot = ifelse( brfss_df12131415161718s$flshtmy2 %in% 12011:122018 , as.numeric( brfss_df12131415161718s$flshtmy2), NA)

#year and state dummies
brfss_df12131415161718s$iyear = as.factor(brfss_df12131415161718s$iyear)
brfss_df12131415161718s$imonth = as.factor(brfss_df12131415161718s$imonth)

brfss_df12131415161718s$yearmonth=as.yearmon( paste(brfss_df12131415161718s$iyear, brfss_df12131415161718s$imonth, sep = "." )  , format = "%Y.%m" )
# brfss_df12131415161718s$yearmonth = as.factor(brfss_df12131415161718s$yearmonth)
brfss_df12131415161718s=na.omit(brfss_df12131415161718s)


brfss_df12131415161718s$when_flushot=as.character(brfss_df12131415161718s$when_flushot)
# brfss_df12131415161718s$when_flushot=as.factor(brfss_df12131415161718s$when_flushot)
# glimpse(brfss_df12131415161718s$when_flushot)
brfss_df12131415161718s$when_flushot <- sub("^", "0", brfss_df12131415161718s$when_flushot)

x=brfss_df12131415161718s$when_flushot

substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}
brfss_df12131415161718s$year_flushot= substrRight(x, 4)
brfss_df12131415161718s$test_year_flushot= substrRight(x, 6)

y=brfss_df12131415161718s$test_year_flushot
brfss_df12131415161718s$month_flushot= substr(y, 1 , 2)

brfss_df12131415161718s$month_flushot=as.numeric(brfss_df12131415161718s$month_flushot)
brfss_df12131415161718s$year_flushot=as.numeric(brfss_df12131415161718s$year_flushot)

brfss_df12131415161718s$time_flushot=as.yearmon( paste(brfss_df12131415161718s$year_flushot, brfss_df12131415161718s$month_flushot, sep = "." )  , format = "%Y.%m" )

interview_count.obs = brfss_df12131415161718s %>% count(yearmonth)
interview_count.obs$yearmonth = as.yearmon(interview_count.obs$yearmonth)
interview_count.obs=head(interview_count.obs,-3)
# Number of respondents
plot(as.zoo(interview_count.obs$yearmonth),as.zoo(interview_count.obs$n),
     type='l',
     col = "steelblue",
     lwd = 2,
     ylab = "# Respondents",
     xlab = "Date",
     main = "Number of People Interviewed")



brfss_fludata= brfss_df12131415161718s %>% count(time_flushot)
brfss_fludata$time_flushot=as.yearmon(brfss_fludata$time_flushot)
brfss_fludata$n=as.numeric(brfss_fludata$n)

#get rid of the last 8 unreseanable rows and half of 2018 because there are not enough people. Usually 2019 data will be reported for 2018 shot taken
brfss_fludata=head(brfss_fludata,-14)
brfss_fludata$log_brfss_number_of_people_taken_flushot=log(brfss_fludata$n)

plot(as.zoo(brfss_fludata$time_flushot),brfss_fludata$n, type="l")
plot(as.zoo(brfss_fludata$time_flushot),brfss_fludata$log_brfss_number_of_people_taken_flushot, type="l")


plot(as.zoo(brfss_fludata$time_flushot),as.zoo(brfss_fludata$log_brfss_number_of_people_taken_flushot),
     type='l',
     col = "steelblue",
     lwd = 2,
     ylab = "Number of People",
     xlab = "Date",
     main = "Number of People Taken Flu Shot")
```

```{r,include=FALSE, echo=FALSE}
#Google data
google_flu <- read.csv(file = 'multiTimeline.csv')
google_flu$time_flushot=as.yearmon(google_flu$Month)
google_flu$google_n=as.numeric(google_flu$flu.shot)

plot(as.zoo(google_flu$time_flushot),google_flu$google_n, type="l")

plot(as.zoo(google_flu$time_flushot),as.zoo(google_flu$google_n),
     type='l',
     col = "steelblue",
     lwd = 2,
     ylab = "Number of People",
     xlab = "Date",
     main = "Number of People Taken Flu Shot")

```



```{r,include=FALSE, echo=FALSE}
plot(as.zoo(brfss_fludata$time_flushot),brfss_fludata$log_brfss_number_of_people_taken_flushot, type="l")
plot(as.zoo(brfss_fludata$time_flushot),brfss_fludata$n, type="l")

plot(as.zoo(google_flu$time_flushot),google_flu$google_n, type="l")
```

```{r,include=FALSE, echo=FALSE}
flu_predicttrend=merge(brfss_fludata,google_flu, by="time_flushot")

#using google method /100 for brfss data
flu_predicttrend$new_brfss_n=(flu_predicttrend$n)/(max(flu_predicttrend$n))*100
flu_predicttrend$log_brfss_new_n=log(flu_predicttrend$new_brfss_n)

#Include dummies for:
flu_predicttrend$fluoutbreak=0
#In comparison to other recent seasons, the 2012-2013 season was moderately severe, with a high percentage of outpatient visits for influenza-like illness (ILI), high rates of hospitalization (particularly among people 65 years and older), and more reported deaths attributed to pneumonia and influenza compared with recent years. https://www.cdc.gov/flu/pastseasons/1213season.htm 
flu_predicttrend$fluoutbreak[25]=1 #Jan 2013

#Flu activity peaked during the week ending December 28, 2013 for the 2013-2014 season. 2009 H1N1 viruses predominated overall during the 2013-14 flu season. https://www.cdc.gov/flu/pastseasons/1314season.htm 
flu_predicttrend$fluoutbreak[37]=1 #Jan 2014

#Compared with the previous five influenza seasons, the 2014-2015 season was moderately severe
#While there were reports of severe flu illnesses and deaths, overall the 2015-2016 season was milder than the previous three seasons.
#flu activity during the 2016-2017 season had been moderate

#The 2017-2018 influenza season was a high severity season 
flu_predicttrend$fluoutbreak[85]=1 #Jan 2018








```


```{r,include=FALSE, echo=FALSE}
#Some interesting ideas:
# Take the total number of people who have bad mental health for each month and merge with https://www.census.gov/retail/marts/www/timeseries.html under Health and personal care stores
# take the total number of people who are overweight and combine with this dataset: https://www.census.gov/retail/marts/www/timeseries.html under foood and bererage to see whether number of food and drinking places have an effect on the number of overweight people?
p = ggplot() + 
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = log_brfss_number_of_people_taken_flushot), color = "blue") +
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = log(google_n)), color = "red") +
  xlab('Dates') +
  ylab('percent.change') 
print(p)

p1 = ggplot() + 
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = log_brfss_new_n), color = "blue") +
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = log(google_n)), color = "red") +
  xlab('Dates') +
  ylab('percent.change')
print(p1)

p2 = ggplot() + 
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = new_brfss_n), color = "blue") +
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = google_n), color = "red") +
  xlab('Dates') +
  ylab('percent.change')
print(p2)

```


```{r,include=FALSE, echo=FALSE}
#standard lag for true data
flu_predicttrend_lag <- slide(flu_predicttrend, Var = "log_brfss_number_of_people_taken_flushot", slideBy = -1)
flu_predicttrend_lag <- slide(flu_predicttrend_lag, Var = "log_brfss_number_of_people_taken_flushot", slideBy = -12)

#lag for Google/100 method 
flu_predicttrend_lag <- slide(flu_predicttrend_lag, Var = "log_brfss_new_n", slideBy = -1)
flu_predicttrend_lag <- slide(flu_predicttrend_lag, Var = "log_brfss_new_n", slideBy = -12)

#rename
flu_predicttrend_lag$lag1=flu_predicttrend_lag$`log_brfss_number_of_people_taken_flushot-1`
flu_predicttrend_lag$lag12=flu_predicttrend_lag$`log_brfss_number_of_people_taken_flushot-12`
flu_predicttrend_lag$new_lag1=flu_predicttrend_lag$`log_brfss_new_n-1`
flu_predicttrend_lag$new_lag12=flu_predicttrend_lag$`log_brfss_new_n-12`


#Regression

#Using BRFSS/max*100
testlm_google.100method_nooutbreak = lm(log_brfss_new_n ~  new_lag1 + new_lag12 + google_n , data = flu_predicttrend_lag)
sum_testlm_google.100method_nooutbreak=summary(testlm_google.100method_nooutbreak)
sum_testlm_google.100method_nooutbreak

testlm_google.100method = lm(log_brfss_new_n ~  new_lag1 + new_lag12 + google_n + fluoutbreak , data = flu_predicttrend_lag)
sum_testlm_google.100method=summary(testlm_google.100method)
sum_testlm_google.100method

par(mfrow = c(2, 2))  # Split the plotting panel into a 2 x 2 grid
plot(testlm_google.100method)

#Using standard data
testlm_nooutbreak = lm(log_brfss_number_of_people_taken_flushot ~  lag1 + lag12 + google_n, data = flu_predicttrend_lag)
sum_testlm_nooutbreak=summary(testlm_nooutbreak)
sum_testlm_nooutbreak

testlm = lm(log_brfss_number_of_people_taken_flushot ~  lag1 + lag12 + google_n + fluoutbreak, data = flu_predicttrend_lag)
sum_testlm=summary(testlm)
sum_testlm

par(mfrow = c(2, 2))  # Split the plotting panel into a 2 x 2 grid
plot(testlm)

#Note: 2012 is that last year that asks when did the respondents take the flushots, so we can add another year.
```

```{r,include=FALSE, echo=FALSE}
latex_results1=stargazer(testlm_nooutbreak, testlm, type="latex", column.labels = c("Model 1", "Model 2"), title="Seasonal AR Model")

latex_results2=stargazer(testlm_google.100method_nooutbreak,testlm_google.100method, type="latex", column.labels = c("Model 3", "Model 4"), title="Seasonal AR Model - Transformed Dependent Variable")

```

# Motivation

Can Google Trends predict Health Behavior? This paper uses the largest search engine in the world to predict human behavior regarding one of the hottest topics in the history of health behavior in America. This paper provides insights on how Artificial Intelligence (AI) flatform such as Google Trends can predict the time, the scale and the magnitude of flu vaccination intakes in America. Using the Behavioral Risk Factor Surveillance System (BRFSS) dataset from 2012-2018 and Google Trends queries looking for the term "flu shot", this paper aims to answer whether query data correlate with the current level of health activity, and if so, could it be helpful in predicting the subsequent data releases. 

Why do we care? The short answer is to predict on the scale of people who are taking the flu shot each year, and thus give authorities the tools to properly prepare for major surges in flu outbreaks. 

Big data could prevent situations such as this, helping communities better prepare for the flu and ultimately save lives. Mining non-traditional data sources such as social media and Google search patterns in addition to electronic health records (EHRs), could arm medical providers with more accurate and contextually-rich insights. In fact, studies have already proven that unexpected data sources such as Twitter can accurately predict flu outbreaks up to six weeks before they happen — far sooner than the models we currently rely on. 

This paper takes a different approach. This paper does not forcast the outbreak necessarily, but it forcasts the number of incoming people who need flu-fighting antiviral drugs. Therefore, this paper partly works on the subset of people who are not necessarily ill from the flu. Why is it important? The importance of these prediction models cannot be overstated: Last year’s incorrect flu forecasts resulted in shortages of flu-fighting antiviral drugs in many clinics, and hospitals were ill-prepared to care for the unexpected influx of patients. In other words, rather than relying on the flu-rate or patient visits data, this paper gives prediction bases on flu-shot rate. 

There is no doubt that more and more people are taking flu vaccination through out the years. According to the CDC, these numbers are rising from 10% in 2004 to 45% of the US population in 2019. Therefore, having a model that can predict these numbers to precise estimates is essential. By predicting it right, we can prevent shortages of flu-fighting vaccination, and we can better prepare for the next flu-season. 

Given what is happening now with the coronavirus, more and more people will be taking flu-shot and thus having a prediction model for flu-shot takers is essential. 


# Data, Empirical Model and Methodology

Our data of flu shots takens come from the Behavioral Risk Factor Surveillance System (BRFSS) from 2012-2018, maintained by the Center for Disease Control and Prevention (CDC) to monitor health and behavioral risk in the U.S. Relying on previous literature, Seasonal autoregressive (AR) model for this paper is given by:

$$log(y_t)=log(y_{t-1})+log(y_{t-12}) + x_t + \tau_t +  \epsilon_t$$
where $y$ is the number of people who take flu shots at time $t$. Because Google Trends data is based on the popularity of the searches, I impose the same method for flu shot takers in the BRFSS survey. Google data represents search interest relative to the highest point on the period of interest for the given region. In simple terms, a maximum value of 100 in Google data is the peak popularity for the term, a value of 50 means that the term is half as popular while a score of 0 means there was not enough data for this term. Therefore, to properly set up the data, $y$ is transformed into the fraction of flu shot takers in a certain month, divided by the highest number of people in the whole periods. $x_t$ is the query index for ‘Flu Shot’ from 2012-2018. The reason it goes back to 2012 instead of 2013 is because of the nature of the question in the BRFSS survey. The survey question specifically asks the respondents when they took the shots in the last 12 months, in which the answers for 2013 respondents range all the way down to January 2012. $\tau_t$ is the dummy for Outbreaks, which is the only major outbreak that caught the most attention during the 2018 period. $\epsilon_t$ is the error term. 

Here are the respondents who have taken the flu shots during 2013-2018 period.


```{r}
# Number of respondents
plot(as.zoo(interview_count.obs$yearmonth),as.zoo(interview_count.obs$n),
     type='l',
     col = "steelblue",
     lwd = 2,
     ylab = "# Respondents",
     xlab = "Date",
     main = "Number of People Interviewed")
```


Down below are the trends representing the percentage change in flu shot takers for BRFSS data and Google Data. In the first figure, blue line is the percentage change in the number of people who have taken the flu shots WITHOUT transforming the scale in the BRFSS, while the red line is the percentage change in the search queries for the term "flu shot". Note that by saying “without changing the scale,” I mean that the flu shot takers data from the BRFSS will be given as it is, or there is no change. And by transforming the scale, I mean that the flu shot takers data from the BRFSS will be changed with the maximum number of respondents being 100. So, this method is similar to the Google Trends popularity method. In the second figure, the blue line is the popularity of the number of people who have taken the flu shots after transforming the scale while the red line is the popularity of the search queries for the term "flu shot."


```{r}
ggplot() + 
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = log_brfss_number_of_people_taken_flushot), color = "blue") +
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = log(google_n)), color = "red") +
  xlab('Dates') +
  ylab('percent.change') 

```

```{r}
ggplot() + 
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = new_brfss_n), color = "blue") +
  geom_line(data = flu_predicttrend, aes(x = time_flushot, y = google_n), color = "red") +
  xlab('Dates') +
  ylab('percent.change')

```



# Results

\begin{table}[!htbp] \centering 
  \caption{Seasonal AR Model} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{2}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & \multicolumn{2}{c}{log\_brfss\_number\_of\_people\_taken\_flushot} \\ 
 & Model 1 & Model 2 \\ 
\\[-1.8ex] & (1) & (2)\\ 
\hline \\[-1.8ex] 
 lag1 & 0.225$^{***}$ & 0.214$^{***}$ \\ 
  & (0.055) & (0.053) \\ 
  & & \\ 
 lag12 & 0.541$^{***}$ & 0.461$^{***}$ \\ 
  & (0.060) & (0.064) \\ 
  & & \\ 
 google\_n & 0.016$^{***}$ & 0.028$^{***}$ \\ 
  & (0.005) & (0.006) \\ 
  & & \\ 
 fluoutbreak &  & $-$1.029$^{***}$ \\ 
  &  & (0.351) \\ 
  & & \\ 
 Constant & 1.803$^{***}$ & 2.407$^{***}$ \\ 
  & (0.442) & (0.469) \\ 
  & & \\ 
\hline \\[-1.8ex] 
Observations & 77 & 77 \\ 
R$^{2}$ & 0.906 & 0.916 \\ 
Adjusted R$^{2}$ & 0.902 & 0.911 \\ 
Residual Std. Error & 0.489 (df = 73) & 0.465 (df = 72) \\ 
F Statistic & 234.280$^{***}$ (df = 3; 73) & 196.193$^{***}$ (df = 4; 72) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 

\begin{table}[!htbp] \centering 
  \caption{Seasonal AR Model - Transformed Dependent Variable} 
  \label{} 
\begin{tabular}{@{\extracolsep{5pt}}lcc} 
\\[-1.8ex]\hline 
\hline \\[-1.8ex] 
 & \multicolumn{2}{c}{\textit{Dependent variable:}} \\ 
\cline{2-3} 
\\[-1.8ex] & \multicolumn{2}{c}{log\_brfss\_new\_n} \\ 
 & Model 3 & Model 4 \\ 
\\[-1.8ex] & (1) & (2)\\ 
\hline \\[-1.8ex] 
 new\_lag1 & 0.225$^{***}$ & 0.214$^{***}$ \\ 
  & (0.055) & (0.053) \\ 
  & & \\ 
 new\_lag12 & 0.541$^{***}$ & 0.461$^{***}$ \\ 
  & (0.060) & (0.064) \\ 
  & & \\ 
 google\_n & 0.016$^{***}$ & 0.028$^{***}$ \\ 
  & (0.005) & (0.006) \\ 
  & & \\ 
 fluoutbreak &  & $-$1.029$^{***}$ \\ 
  &  & (0.351) \\ 
  & & \\ 
 Constant & 0.214$^{**}$ & 0.202$^{**}$ \\ 
  & (0.082) & (0.078) \\ 
  & & \\ 
\hline \\[-1.8ex] 
Observations & 77 & 77 \\ 
R$^{2}$ & 0.906 & 0.916 \\ 
Adjusted R$^{2}$ & 0.902 & 0.911 \\ 
Residual Std. Error & 0.489 (df = 73) & 0.465 (df = 72) \\ 
F Statistic & 234.280$^{***}$ (df = 3; 73) & 196.193$^{***}$ (df = 4; 72) \\ 
\hline 
\hline \\[-1.8ex] 
\textit{Note:}  & \multicolumn{2}{r}{$^{*}$p$<$0.1; $^{**}$p$<$0.05; $^{***}$p$<$0.01} \\ 
\end{tabular} 
\end{table} 


```{r,fig4, out.width = '70%', echo=FALSE, ,fig.align='center',fig.cap= 'Diagnostic Plots for the Regression Model'}
par(mfrow = c(2, 2))  # Split the plotting panel into a 2 x 2 grid
plot(testlm_google.100method)
```





